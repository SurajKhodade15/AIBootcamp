{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61dc3579",
   "metadata": {},
   "source": [
    "## 1. Definition of Perceptron\n",
    "The Perceptron is the most basic form of an artificial neural network, introduced by Frank Rosenblatt in 1958.\n",
    "It is a binary linear classifier that maps its input \n",
    "ğ‘¥\n",
    "x (a vector of numerical values) to an output \n",
    "ğ‘¦\n",
    "y (0 or 1) using a weighted sum and an activation function.\n",
    "\n",
    "## 2. Mathematical Model\n",
    "The perceptron consists of:\n",
    "\n",
    "Inputs \n",
    "ğ‘¥\n",
    "1\n",
    ",\n",
    "ğ‘¥\n",
    "2\n",
    ",\n",
    "â€¦\n",
    ",\n",
    "ğ‘¥\n",
    "ğ‘›\n",
    "x \n",
    "1\n",
    "â€‹\n",
    " ,x \n",
    "2\n",
    "â€‹\n",
    " ,â€¦,x \n",
    "n\n",
    "â€‹\n",
    " \n",
    "\n",
    "Weights \n",
    "ğ‘¤\n",
    "1\n",
    ",\n",
    "ğ‘¤\n",
    "2\n",
    ",\n",
    "â€¦\n",
    ",\n",
    "ğ‘¤\n",
    "ğ‘›\n",
    "w \n",
    "1\n",
    "â€‹\n",
    " ,w \n",
    "2\n",
    "â€‹\n",
    " ,â€¦,w \n",
    "n\n",
    "â€‹\n",
    " \n",
    "\n",
    "Bias \n",
    "ğ‘\n",
    "b\n",
    "\n",
    "Activation Function \n",
    "ğ‘“\n",
    "(\n",
    "â‹…\n",
    ")\n",
    "f(â‹…) (commonly a step function)\n",
    "\n",
    "The output is calculated as:\n",
    "\n",
    "ğ‘¦\n",
    "=\n",
    "ğ‘“\n",
    "(\n",
    "âˆ‘\n",
    "ğ‘–\n",
    "=\n",
    "1\n",
    "ğ‘›\n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "ğ‘¥\n",
    "ğ‘–\n",
    "+\n",
    "ğ‘\n",
    ")\n",
    "y=f( \n",
    "i=1\n",
    "âˆ‘\n",
    "n\n",
    "â€‹\n",
    " w \n",
    "i\n",
    "â€‹\n",
    " x \n",
    "i\n",
    "â€‹\n",
    " +b)\n",
    "Where:\n",
    "\n",
    "If the weighted sum > threshold â†’ output \n",
    "ğ‘¦\n",
    "=\n",
    "1\n",
    "y=1\n",
    "\n",
    "Else â†’ output \n",
    "ğ‘¦\n",
    "=\n",
    "0\n",
    "y=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02d8c3",
   "metadata": {},
   "source": [
    "## 3. Architecture of a Perceptron\n",
    "Input Layer â†’ Weighted Sum â†’ Activation (Step) â†’ Output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e7b985",
   "metadata": {},
   "source": [
    "## 4. Learning Algorithm (Perceptron Learning Rule)\n",
    "Initialize weights \n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "w \n",
    "i\n",
    "â€‹\n",
    "  and bias \n",
    "ğ‘\n",
    "b to small random values.\n",
    "\n",
    "For each training sample:\n",
    "\n",
    "Compute predicted output \n",
    "ğ‘¦\n",
    "â€²\n",
    "y \n",
    "â€²\n",
    " \n",
    "\n",
    "Update weights if prediction is wrong:\n",
    "\n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "=\n",
    "ğ‘¤\n",
    "ğ‘–\n",
    "+\n",
    "ğœ‚\n",
    "(\n",
    "ğ‘¦\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "â€²\n",
    ")\n",
    "ğ‘¥\n",
    "ğ‘–\n",
    "w \n",
    "i\n",
    "â€‹\n",
    " =w \n",
    "i\n",
    "â€‹\n",
    " +Î·(yâˆ’y \n",
    "â€²\n",
    " )x \n",
    "i\n",
    "â€‹\n",
    " \n",
    "ğ‘\n",
    "=\n",
    "ğ‘\n",
    "+\n",
    "ğœ‚\n",
    "(\n",
    "ğ‘¦\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "â€²\n",
    ")\n",
    "b=b+Î·(yâˆ’y \n",
    "â€²\n",
    " )\n",
    "Where \n",
    "ğœ‚\n",
    "Î· is the learning rate.\n",
    "\n",
    "Repeat until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dc74c",
   "metadata": {},
   "source": [
    "## 5. Characteristics\n",
    "Type: Supervised Learning Algorithm\n",
    "\n",
    "Output: Binary classification (0 or 1)\n",
    "\n",
    "Model: Linear classifier (decision boundary is a straight line/hyperplane)\n",
    "\n",
    "## 6. Limitations\n",
    "Can only classify linearly separable data (e.g., AND, OR gates work; XOR fails).\n",
    "\n",
    "Cannot learn complex decision boundaries without multiple layers.\n",
    "\n",
    "## 7. Example Use Case\n",
    "Early models for image recognition\n",
    "\n",
    "Binary classification tasks (spam vs. not spam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc997593",
   "metadata": {},
   "source": [
    "## Advantages And Disadvantages\n",
    "| **Aspect**            | **Advantages**                                                  | **Disadvantages**                                                      |\n",
    "| --------------------- | --------------------------------------------------------------- | ---------------------------------------------------------------------- |\n",
    "| **Simplicity**        | Easy to implement and computationally efficient.                | Too simplistic to handle complex patterns.                             |\n",
    "| **Learning**          | Guaranteed to converge for linearly separable data.             | Fails when data is not linearly separable (e.g., XOR problem).         |\n",
    "| **Architecture**      | Forms the foundation for building more complex neural networks. | Lacks hidden layers, limiting its learning capability.                 |\n",
    "| **Scalability**       | Works well for small, simple datasets.                          | Does not scale efficiently to complex datasets without modifications.  |\n",
    "| **Output**            | Provides a clear binary decision boundary.                      | Only supports binary classification; cannot output probabilities.      |\n",
    "| **Training Dynamics** | Can perform online (incremental) learning efficiently.          | Sensitive to learning rate and initial weights, affecting convergence. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1cce4e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
