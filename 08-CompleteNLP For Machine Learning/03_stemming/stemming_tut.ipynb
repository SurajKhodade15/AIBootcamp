{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea72c675",
   "metadata": {},
   "source": [
    "## ðŸŒ¿ Stemming in NLTK\n",
    "\n",
    "ðŸ“– Definition:\n",
    "Stemming is the process of reducing words to their root or base form, typically by removing suffixes. It is a rule-based text preprocessing technique used to normalize words for downstream NLP tasks such as search, classification, and clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da960360",
   "metadata": {},
   "source": [
    "### ðŸŒ¿ Stemming Techniques in NLTK\n",
    "| Stemmer              | Type                      | Description                                                                 |\n",
    "| -------------------- | ------------------------- | --------------------------------------------------------------------------- |\n",
    "| **PorterStemmer**    | Rule-based                | Oldest and widely used; simple suffix-stripping based on fixed rules.       |\n",
    "| **LancasterStemmer** | Rule-based (aggressive)   | More aggressive and faster; uses an iterative rule set to strip suffixes.   |\n",
    "| **SnowballStemmer**  | Rule-based (multilingual) | Successor of PorterStemmer, supports multiple languages with refined rules. |\n",
    "| **RegexpStemmer**    | Regex-based               | Allows custom suffix stripping using regular expressions.                   |\n",
    "| **ISRIStemmer**      | Rule-based (Arabic only)  | Specialized for Arabic morphology using root-based heuristics.              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944e2d1",
   "metadata": {},
   "source": [
    "### ðŸ Summary of Differences\n",
    "| Stemmer       | Strength                   | Limitation               | Use Case                   |\n",
    "| ------------- | -------------------------- | ------------------------ | -------------------------- |\n",
    "| **Porter**    | Stable, interpretable      | May miss complex forms   | Classic NLP preprocessing  |\n",
    "| **Lancaster** | Fast, compact              | Over-stemming possible   | Space-limited environments |\n",
    "| **Snowball**  | Best balance, multilingual | English version â‰ˆ Porter | Enterprise-level NLP       |\n",
    "| **Regexp**    | Fully customizable         | Language agnostic, naive | Domain-specific stemming   |\n",
    "| **ISRI**      | Specialized Arabic support | Only for Arabic          | Arabic NLP systems         |\n",
    "\n",
    "### ðŸŽ¯ Recommendation Matrix\n",
    "\n",
    "| Use Case                        | Recommended Stemmer |\n",
    "| ------------------------------- | ------------------- |\n",
    "| General English NLP             | `SnowballStemmer`   |\n",
    "| Academic NLP Research           | `PorterStemmer`     |\n",
    "| Performance-Constrained Systems | `LancasterStemmer`  |\n",
    "| Custom Rule Scenarios           | `RegexpStemmer`     |\n",
    "| Arabic Language Projects        | `ISRIStemmer`       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03107e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Original   : compute\n",
      "Porter     : comput\n",
      "Lancaster  : comput\n",
      "Snowball   : comput\n",
      "Regexp     : compute\n",
      "============================================================\n",
      "Original   : computing\n",
      "Porter     : comput\n",
      "Lancaster  : comput\n",
      "Snowball   : comput\n",
      "Regexp     : comput\n",
      "============================================================\n",
      "Original   : computer\n",
      "Porter     : comput\n",
      "Lancaster  : comput\n",
      "Snowball   : comput\n",
      "Regexp     : comput\n",
      "============================================================\n",
      "Original   : computed\n",
      "Porter     : comput\n",
      "Lancaster  : comput\n",
      "Snowball   : comput\n",
      "Regexp     : comput\n",
      "============================================================\n",
      "Original   : computation\n",
      "Porter     : comput\n",
      "Lancaster  : comput\n",
      "Snowball   : comput\n",
      "Regexp     : computa\n",
      "============================================================\n",
      "Original   : computationally\n",
      "Porter     : comput\n",
      "Lancaster  : comput\n",
      "Snowball   : comput\n",
      "Regexp     : computational\n",
      "============================================================\n",
      "Original   : connect\n",
      "Porter     : connect\n",
      "Lancaster  : connect\n",
      "Snowball   : connect\n",
      "Regexp     : connect\n",
      "============================================================\n",
      "Original   : connected\n",
      "Porter     : connect\n",
      "Lancaster  : connect\n",
      "Snowball   : connect\n",
      "Regexp     : connect\n",
      "============================================================\n",
      "Original   : connection\n",
      "Porter     : connect\n",
      "Lancaster  : connect\n",
      "Snowball   : connect\n",
      "Regexp     : connec\n",
      "============================================================\n",
      "Original   : connecting\n",
      "Porter     : connect\n",
      "Lancaster  : connect\n",
      "Snowball   : connect\n",
      "Regexp     : connect\n",
      "============================================================\n",
      "Original   : connectional\n",
      "Porter     : connect\n",
      "Lancaster  : connect\n",
      "Snowball   : connect\n",
      "Regexp     : connectional\n",
      "============================================================\n",
      "Original   : quickly\n",
      "Porter     : quickli\n",
      "Lancaster  : quick\n",
      "Snowball   : quick\n",
      "Regexp     : quick\n",
      "============================================================\n",
      "Original   : happily\n",
      "Porter     : happili\n",
      "Lancaster  : happy\n",
      "Snowball   : happili\n",
      "Regexp     : happi\n",
      "============================================================\n",
      "Original   : national\n",
      "Porter     : nation\n",
      "Lancaster  : nat\n",
      "Snowball   : nation\n",
      "Regexp     : national\n",
      "============================================================\n",
      "Original   : nationalist\n",
      "Porter     : nationalist\n",
      "Lancaster  : nat\n",
      "Snowball   : nationalist\n",
      "Regexp     : nationalist\n",
      "============================================================\n",
      "Original   : nationalism\n",
      "Porter     : nation\n",
      "Lancaster  : nat\n",
      "Snowball   : nation\n",
      "Regexp     : nationalism\n",
      "============================================================\n",
      "Original   : relational\n",
      "Porter     : relat\n",
      "Lancaster  : rel\n",
      "Snowball   : relat\n",
      "Regexp     : relational\n",
      "============================================================\n",
      "Original   : organizational\n",
      "Porter     : organiz\n",
      "Lancaster  : org\n",
      "Snowball   : organiz\n",
      "Regexp     : organizational\n",
      "============================================================\n",
      "Original   : communication\n",
      "Porter     : commun\n",
      "Lancaster  : commun\n",
      "Snowball   : communic\n",
      "Regexp     : communica\n",
      "============================================================\n",
      "Original   : running\n",
      "Porter     : run\n",
      "Lancaster  : run\n",
      "Snowball   : run\n",
      "Regexp     : runn\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, RegexpStemmer\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "# Initialize stemmers\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "regexp = RegexpStemmer('ing$|ed$|ly$|tion$|er$', min=4)\n",
    "isri = ISRIStemmer()  # Only works on Arabic text\n",
    "\n",
    "words = [\n",
    "    \"compute\", \"computing\", \"computer\", \"computed\", \"computation\", \"computationally\",\n",
    "    \"connect\", \"connected\", \"connection\", \"connecting\", \"connectional\",\n",
    "    \"quickly\", \"happily\", \n",
    "    \"national\", \"nationalist\", \"nationalism\",\n",
    "    \"relational\", \"organizational\", \"communication\", \"running\"\n",
    "]\n",
    "\n",
    "# Apply each stemmer\n",
    "output = {\n",
    "    \"Original\": words,\n",
    "    \"Porter\": [porter.stem(w) for w in words],\n",
    "    \"Lancaster\": [lancaster.stem(w) for w in words],\n",
    "    \"Snowball\": [snowball.stem(w) for w in words],\n",
    "    \"Regexp\": [regexp.stem(w) for w in words],\n",
    "}\n",
    "\n",
    "# Display results\n",
    "for i in range(len(words)):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Original   : {output['Original'][i]}\")\n",
    "    print(f\"Porter     : {output['Porter'][i]}\")\n",
    "    print(f\"Lancaster  : {output['Lancaster'][i]}\")\n",
    "    print(f\"Snowball   : {output['Snowball'][i]}\")\n",
    "    print(f\"Regexp     : {output['Regexp'][i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c4e4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c0673cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e94e9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"running\", \"ran\", \"easily\", \"fairly\",\"ArithmeticError\", \"arithmetic\", \"arithmeticity\",\"optimization\", \"optimizing\", \"optimizes\",\"finally\", \"finalize\", \"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c5581b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> run\n",
      "ran -> ran\n",
      "easily -> easili\n",
      "fairly -> fairli\n",
      "ArithmeticError -> arithmeticerror\n",
      "arithmetic -> arithmet\n",
      "arithmeticity -> arithmet\n",
      "optimization -> optim\n",
      "optimizing -> optim\n",
      "optimizes -> optim\n",
      "finally -> final\n",
      "finalize -> final\n",
      "finalized -> final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"{word} -> {stemming.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e77f1726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0276d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "066ce23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemming = RegexpStemmer('ing$|ly$|ed$|s$',min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ad4bdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> runn\n",
      "ran -> ran\n",
      "easily -> easi\n",
      "fairly -> fair\n",
      "ArithmeticError -> ArithmeticError\n",
      "arithmetic -> arithmetic\n",
      "arithmeticity -> arithmeticity\n",
      "optimization -> optimization\n",
      "optimizing -> optimiz\n",
      "optimizes -> optimize\n",
      "finally -> final\n",
      "finalize -> finalize\n",
      "finalized -> finaliz\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"{word} -> {reg_stemming.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b021a8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -> run\n",
      "ran -> ran\n",
      "easily -> easili\n",
      "fairly -> fair\n",
      "ArithmeticError -> arithmeticerror\n",
      "arithmetic -> arithmet\n",
      "arithmeticity -> arithmet\n",
      "optimization -> optim\n",
      "optimizing -> optim\n",
      "optimizes -> optim\n",
      "finally -> final\n",
      "finalize -> final\n",
      "finalized -> final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "for word in words:\n",
    "    print(f\"{word} -> {snowball_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "657a6270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laufen -> lauf\n",
      "lÃ¤uft -> lauft\n",
      "gelaufen -> gelauf\n",
      "laufend -> laufend\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"german\")\n",
    "for word in [\"laufen\", \"lÃ¤uft\", \"gelaufen\", \"laufend\"]:\n",
    "    print(f\"{word} -> {snowball_stemmer.stem(word)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
